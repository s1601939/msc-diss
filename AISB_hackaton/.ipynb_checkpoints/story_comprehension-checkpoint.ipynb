{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated story comprehension #\n",
    "This notebook shows how to extract background knowledge and relations from a story text. To this end, we use Stanford's NLP parser available to download [here](https://nlp.stanford.edu/software/lex-parser.html#Download).\n",
    "\n",
    "We parsed the following story (`story.txt` file):\n",
    "```\n",
    "Mary was sleeping.\n",
    "Her phone rang.\n",
    "She was annoyed.\n",
    "Mary answered the phone.\n",
    "Ann told the good news to Mary.\n",
    "```\n",
    "\n",
    "with\n",
    "```\n",
    "java -cp \"*\" -Xmx2g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref -file story.txt\n",
    "```\n",
    "This resulted in an xml file `story.txt.xml` that contains all the necessary data to extract relevant information from the story.\n",
    "\n",
    "The next step is to extract this information and represent it as Prolog facts. To this end, we wrote the Python code included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from xml.etree.ElementTree import parse as xml_parse\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the xml file with the parsed story\n",
    "e = xml_parse(\"story.txt.xml\").getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path_tags is a list of tuples: [(tag, attribute, attribute_id), ...]\n",
    "def get_xml_struct(root, path_tags):\n",
    "    current = root\n",
    "    for tag, attribute, attribute_value in path_tags:\n",
    "        for c in current:\n",
    "            if c.tag == tag:\n",
    "                if attribute is not None and attribute_value is not None:\n",
    "                    if c.attrib.get(attribute) == attribute_value:\n",
    "                        current = c\n",
    "                        break\n",
    "                else:\n",
    "                    current = c\n",
    "                    break\n",
    "    return current\n",
    "\n",
    "def get_attrib_value(root, dep_type, dependent=True):\n",
    "    identifiers = {}\n",
    "    for c in root:\n",
    "        if c.tag == \"dep\":\n",
    "            if c.attrib.get(\"type\", \"\") == dep_type:\n",
    "                for d in c:\n",
    "                    if dependent and d.tag == \"dependent\":\n",
    "                        return d.attrib.get(\"idx\", \"\")\n",
    "                    identifiers[d.tag] = d.attrib.get(\"idx\", \"\")\n",
    "    return identifiers\n",
    "\n",
    "def get_token_lemma(tokens, token_id):\n",
    "    for t in tokens:\n",
    "        if t.tag == \"token\" and t.attrib.get(\"id\", \"\") == token_id:\n",
    "            for i in t:\n",
    "                if i.tag == \"lemma\":\n",
    "                    return i.text\n",
    "    return \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ids:\n",
      "['1', '2', '3', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "# get sentences ids\n",
    "sentence_ids = []\n",
    "t = get_xml_struct(e, [(\"document\", None, None), (\"sentences\", None, None)])\n",
    "for c in t:\n",
    "    id = c.attrib.get(\"id\")\n",
    "    if id is not None:\n",
    "        sentence_ids.append(id)\n",
    "\n",
    "print \"Sentence ids:\"\n",
    "print sentence_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'dobj': 'none', 'root': 'sleep', 'nmod': 'none', 'nsubj': 'mary'}, '3': {'dobj': 'none', 'root': 'annoy', 'nmod': 'none', 'nsubj': 'she'}, '2': {'dobj': 'none', 'root': 'ring', 'nmod': 'none', 'nsubj': 'phone'}, '5': {'dobj': 'news', 'root': 'tell', 'nmod': 'mary', 'nsubj': 'ann'}, '4': {'dobj': 'phone', 'root': 'answer', 'nmod': 'none', 'nsubj': 'mary'}}\n"
     ]
    }
   ],
   "source": [
    "sentence_dependencies = {}\n",
    "for sid in sentence_ids:\n",
    "    sentence_structure = {\"root\":\"none\", \"nsubj\":\"none\", \"dobj\":\"none\", \"nmod\":\"none\"}\n",
    "    # get basic-dependencies\n",
    "    basicd = get_xml_struct(e, [(\"document\", None, None), (\"sentences\", None, None), \\\n",
    "                                (\"sentence\", \"id\", sid), (\"dependencies\", \"type\", \"basic-dependencies\")\n",
    "                               ]\n",
    "                           )\n",
    "    # get lemmas\n",
    "    tokens = get_xml_struct(e, [(\"document\", None, None), (\"sentences\", None, None), \\\n",
    "                                (\"sentence\", \"id\", sid), (\"tokens\", None, None)\n",
    "                               ]\n",
    "                           )\n",
    "\n",
    "    for i in [\"nsubj\", \"nsubjpass\"]:\n",
    "        it = get_token_lemma(tokens, get_attrib_value(basicd, i)).lower()\n",
    "        if it != \"none\":\n",
    "            sentence_structure[\"nsubj\"] = it\n",
    "    for i in [\"root\", \"dobj\", \"nmod\"]:\n",
    "        it = get_token_lemma(tokens, get_attrib_value(basicd, i)).lower()\n",
    "        if it != \"none\":\n",
    "            sentence_structure[i] = it\n",
    "    sentence_dependencies[sid] = sentence_structure\n",
    "\n",
    "print sentence_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicates_string = \"\"\n",
    "for i in sorted(sentence_dependencies.keys()):\n",
    "    si = sentence_dependencies[i]\n",
    "    si[\"time\"] = i\n",
    "    \n",
    "    x = \"s(1) :: %(root)s(%(nsubj)s, %(dobj)s, %(nmod)s) at %(time)s.\" % si\n",
    "    \n",
    "    x = x.lower()\n",
    "    predicates_string += x + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing output ##\n",
    "`xml` parsing gives us the following logical representation of the story:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s(1) :: sleep(mary, none, none) at 1.\n",
      "s(1) :: ring(phone, none, none) at 2.\n",
      "s(1) :: annoy(she, none, none) at 3.\n",
      "s(1) :: answer(mary, phone, none) at 4.\n",
      "s(1) :: tell(ann, news, mary) at 5.\n"
     ]
    }
   ],
   "source": [
    "print predicates_string,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the rules to the `extracted_knowledge.pl` file\n",
    "with open(\"extracted_knowledge.pl\", \"w\") as rules_file:\n",
    "    rules_file.write(predicates_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
